{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the\n",
    "    job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n",
    "    \n",
    "        1. first get the webpage https://www.naukri.com/\n",
    "        2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "           in “enter the location” field.\n",
    "        3. Then click the search button.\n",
    "        4. Then scrape the data for the first 10 jobs results you get.\n",
    "        5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                       Data Analyst   \n",
      "1                                       Data Analyst   \n",
      "2                                       Data Analyst   \n",
      "3                                       Data Analyst   \n",
      "4            Business Data Analyst - MIS & Reporting   \n",
      "5                                       Data Analyst   \n",
      "6                                       Data Analyst   \n",
      "7  Inviting Business Analyst –Data Science and In...   \n",
      "8                            Hiring For Data Analyst   \n",
      "9                                Senior Data Analyst   \n",
      "\n",
      "                                       Company Name Experience  \\\n",
      "0                             Super India Tech Mark    0-2 Yrs   \n",
      "1                                 tech mahindra ltd    4-8 Yrs   \n",
      "2              CONDUENT BUSINESS SERVICES INDIA LLP    1-2 Yrs   \n",
      "3           GlaxoSmithKline Pharmaceuticals Limited    2-7 Yrs   \n",
      "4                                  INTERTRUST GROUP    3-7 Yrs   \n",
      "5                          Myntra Designs Pvt. Ltd.    3-6 Yrs   \n",
      "6                          Myntra Designs Pvt. Ltd.    4-8 Yrs   \n",
      "7                     GENPACT India Private Limited    0-4 Yrs   \n",
      "8  Concentrix Daksh Services India Private Limited.    2-7 Yrs   \n",
      "9                                            Cerner    3-5 Yrs   \n",
      "\n",
      "                                            Location  \n",
      "0                     Bangalore/Bengaluru(Devalapur)  \n",
      "1                                Bangalore/Bengaluru  \n",
      "2                                Bangalore/Bengaluru  \n",
      "3                                Bangalore/Bengaluru  \n",
      "4                        Mumbai, Bangalore/Bengaluru  \n",
      "5                                Bangalore/Bengaluru  \n",
      "6                                Bangalore/Bengaluru  \n",
      "7                                Bangalore/Bengaluru  \n",
      "8  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
      "9                                Bangalore/Bengaluru  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_da():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Analyst\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    job_loc.send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_btn.click()  \n",
    "    url = \"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_da()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape\n",
    "    the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "    \n",
    "            1. first get the webpage https://www.naukri.com/\n",
    "            2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "               “Bangalore” in “enter the location” field.\n",
    "            3. Then click the search button.\n",
    "            4. Then scrape the data for the first 10 jobs results you get.\n",
    "            5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                     Data Scientist   \n",
      "1                      Data Scientist - C3 Developer   \n",
      "2  Principal Data Scientist - Product Development...   \n",
      "3                              Senior Data Scientist   \n",
      "4                        Data Scientist - AI ML Team   \n",
      "5       Data Scientist - Algorithm/ Machine Learning   \n",
      "6                              Senior Data Scientist   \n",
      "7                Data Scientist - KPO - IIT/NIT/BITS   \n",
      "8                        Staff Data Scientist (MINT)   \n",
      "9                                     Data Scientist   \n",
      "\n",
      "                          Company Name             Location  \\\n",
      "0                    Fractal Analytics  Bangalore/Bengaluru   \n",
      "1                                                   Chennai   \n",
      "2  Shell India Markets Private Limited  Bangalore/Bengaluru   \n",
      "3                                                 Bangalore   \n",
      "4            hCapital Executive Search                 Pune   \n",
      "5                                       Bangalore/Bengaluru   \n",
      "6                     Avom Consultants          Delhi / NCR   \n",
      "7                                       Bangalore/Bengaluru   \n",
      "8         CustomerXPs Software Pvt Ltd  Bangalore/Bengaluru   \n",
      "9                                       Bangalore/Bengaluru   \n",
      "\n",
      "                                         Description  \n",
      "0  Job description Role Brief: As a NLP Data Scie...  \n",
      "1  Job description The Role Potential candidate w...  \n",
      "2  Job description Principal Data Scientist - Pro...  \n",
      "3  Job description Data Scientist with relevant e...  \n",
      "4  Job description We are seeking sharp, energeti...  \n",
      "5  Job description Roles & Responsibilities :  - ...  \n",
      "6  Job description To Contribute to model generat...  \n",
      "7  Job description - Looking for Data Scientists ...  \n",
      "8  Job description Your Opportunity To fulfill th...  \n",
      "9  Job description  Looking for a Data Scientist ...  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "job_description = []\n",
    "url_list = []\n",
    "\n",
    "\n",
    "def naukri_ds():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    job_loc.send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_btn.click()  \n",
    "    \n",
    "    driver.get('https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore')\n",
    "    \n",
    "    urls = driver.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "    for i in urls:\n",
    "        link = i.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "\n",
    "    for x in url_list[0:15]:\n",
    "        driver.get(x)\n",
    "        time.sleep(5)\n",
    "        for i in driver.find_elements_by_xpath(\"//h1[@class = 'jd-header-title']\"):\n",
    "            job_title.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//a[@class='pad-rt-8'or @class = 'subTitle ellipsis fleft']\"):\n",
    "            comp_name.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//span[@class='location ']/a\"):\n",
    "            location_list.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//section[@class='job-desc']\"):\n",
    "            job_description.append(l.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    jobs['Description'] = job_description[0:10]\n",
    "    print(jobs)\n",
    "    \n",
    "    jobs.to_csv(\"jobs.csv\")\n",
    "\n",
    "# Calling Function\n",
    "naukri_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage.\n",
    "    \n",
    "    The task will be done as shown in the below steps:\n",
    "        1. first get the webpage https://www.naukri.com/\n",
    "        2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "        3. Then click the search button.\n",
    "        4. Then apply the location filter and salary filter by checking the respective boxes.Then scrape the\n",
    "           data for the first 10 jobs results you get.\n",
    "        5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                     Data Scientist   \n",
      "1                                     Data Scientist   \n",
      "2                                     Data Scientist   \n",
      "3                                     Data Scientist   \n",
      "4                                     Data Scientist   \n",
      "5  Data Scientist | Python | Machine Learning | D...   \n",
      "6  Data Scientist/Data Analyst - Python/Machine L...   \n",
      "7  GCP Presales AIML Architect & Data Scientist (...   \n",
      "8  GCP Presales AIML Architect & Data Scientist (...   \n",
      "9                    Data Scientist Machine Learning   \n",
      "\n",
      "                             Company Name Experience                Location  \n",
      "0                           NatWest Group    4-8 Yrs             Delhi / NCR  \n",
      "1  itForte Staffing Services Private Ltd.    3-8 Yrs        Gurgaon/Gurugram  \n",
      "2                                  Msg.ai    3-5 Yrs        Gurgaon/Gurugram  \n",
      "3                           NatWest Group    4-8 Yrs        Gurgaon/Gurugram  \n",
      "4                           NatWest Group    4-8 Yrs             Delhi / NCR  \n",
      "5                               Careerera    3-8 Yrs  Noida(Sector-59 Noida)  \n",
      "6                          Change leaders   5-10 Yrs       Mumbai, Ghaziabad  \n",
      "7                 Lecan Solutions Pvt Ltd   6-11 Yrs                   Noida  \n",
      "8                 Lecan Solutions Pvt Ltd   6-11 Yrs                   Noida  \n",
      "9                               Delhivery    1-3 Yrs        Gurgaon/Gurugram  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_ds_1():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = 'Delhi / NCR']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = '3-6 Lakhs']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_ds_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. \n",
    "    You have to scrape company_name, No. of days ago when job was posted, Rating of the company.This task will be done\n",
    "    in following steps:\n",
    "            1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "            2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "               in “location” field.\n",
    "            3. Then click the search button.\n",
    "            4. Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "               page.\n",
    "            5. Finally create a dataframe of the scraped data.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Company Name Days Posted(ago) Ratings\n",
      "0           BlackRock              14d     4.0\n",
      "1  Ericsson-Worldwide               3d     4.1\n",
      "2              Luxoft               1d     4.2\n",
      "3               Adobe               2d     4.4\n",
      "4      Biz2Credit Inc               3d     3.8\n",
      "5            Techlive               1d     5.0\n",
      "6           dunnhumby               1d     4.2\n",
      "7           Microsoft              14d     4.4\n",
      "8             itForte              23d     5.0\n",
      "9             WishFin               6d     3.8\n"
     ]
    }
   ],
   "source": [
    "days_ago = []\n",
    "comp_name = []\n",
    "ratings = []\n",
    "\n",
    "\n",
    "def glassdoor():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "    \n",
    "    jobs = driver.find_element_by_xpath('//*[@id=\"SrchHero\"]/div/div[1]/div[1]/div/div/div/ul/li[1]')\n",
    "    jobs.click()\n",
    "    \n",
    "    search_job = driver.find_element_by_xpath(\"//input[@id = 'KeywordSearch']\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "    driver.find_element_by_xpath(\"//input[@class='loc']\").clear()\n",
    "    job_loc.send_keys(\"Noida\")\n",
    "    \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@id='HeroSearchButton']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span\"):\n",
    "        comp_name.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob' or @class = 'd-flex align-items-end pl-std css-mi55ob']\"):\n",
    "        days_ago.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\"):\n",
    "        ratings.append(k.text)\n",
    "    \n",
    "        \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Days Posted(ago)'] = days_ago[0:10]\n",
    "    jobs['Ratings'] = ratings[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "glassdoor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to\n",
    "    scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.The above task will be, done as\n",
    "    shown in the below steps:\n",
    "            1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "            2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "            3. Click the search button.\n",
    "            4. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary\n",
    "               and rating of the company.\n",
    "            5.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Company Name Total Salaries  Average Salary Min and Max Salary\n",
      "0  Tata Consultancy Services    14 salaries   ₹ 6,01,000/yr      ₹336L ₹1,080L\n",
      "1                  Accenture    14 salaries  ₹ 11,51,207/yr      ₹579L ₹2,222L\n",
      "2                  Delhivery    14 salaries  ₹ 12,34,207/yr     ₹452L ₹11,669L\n",
      "3                        IBM    13 salaries   ₹ 7,63,825/yr      ₹589L ₹2,741L\n",
      "4         Ericsson-Worldwide    12 salaries   ₹ 7,32,209/yr      ₹350L ₹1,619L\n",
      "5         UnitedHealth Group    10 salaries  ₹ 13,88,910/yr    ₹1,050L ₹1,500L\n",
      "6         Valiance Solutions     9 salaries   ₹ 8,18,515/yr      ₹504L ₹1,471L\n",
      "7                 Innovaccer     8 salaries  ₹ 12,01,403/yr      ₹623L ₹1,702L\n",
      "8              ZS Associates     7 salaries  ₹ 10,00,000/yr      ₹203L ₹1,817L\n",
      "9                EXL Service     7 salaries  ₹ 11,90,000/yr      ₹578L ₹1,500L\n"
     ]
    }
   ],
   "source": [
    "salary_no = []\n",
    "comp_name = []\n",
    "avg_sal = []\n",
    "min_sal = []\n",
    "\n",
    "def glassdoor_salary():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "    \n",
    "    search_job = driver.find_element_by_xpath(\"//input[@id = 'KeywordSearch']\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "    driver.find_element_by_xpath(\"//input[@class='loc']\").clear()   \n",
    "    job_loc.send_keys(\"Noida\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@id='HeroSearchButton']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "        comp_name.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "        salary_no.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "        avg_sal.append(k.text.replace(\"\\n\",\"\"))\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']\"):\n",
    "        min_sal.append(l.text.replace(\"\\n\",\" \"))\n",
    "      \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Total Salaries'] = salary_no[0:10]\n",
    "    jobs['Average Salary'] = avg_sal[0:10]\n",
    "    jobs['Min and Max Salary'] = min_sal[0:10]\n",
    "    \n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "glassdoor_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "        1. Brand\n",
    "        2. Product Description\n",
    "        3. Price\n",
    "        4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Brand                                        Description Price Discount\n",
      "0   Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758  15% off\n",
      "1   Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹499  50% off\n",
      "2     PIRASO              UV Protection Aviator Sunglasses (54)  ₹225  85% off\n",
      "3     PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹349  78% off\n",
      "4   Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹733  18% off\n",
      "..       ...                                                ...   ...      ...\n",
      "95      hipe  UV Protection, Gradient, Riding Glasses Wayfar...  ₹249  75% off\n",
      "96    Aislin       UV Protection, Gradient Oval Sunglasses (58)  ₹469  69% off\n",
      "97  Fastrack          UV Protection Rectangular Sunglasses (56)  ₹689  13% off\n",
      "98    PIRASO              UV Protection Aviator Sunglasses (58)  ₹314  87% off\n",
      "99  Fastrack   UV Protection Wrap-around Sunglasses (Free Size)  ₹865   3% off\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_sunglass():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/\")\n",
    "    pop_btn = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    pop_btn.click()\n",
    "    \n",
    "    search_job = driver.find_element_by_xpath(\"//input[@type = 'text']\")\n",
    "    search_job.send_keys(\"sunglasses\") \n",
    "    \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    driver.get(\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for i in url:\n",
    "        link = i.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "\n",
    "    for x in url_list[0:6]:\n",
    "        driver.get(x)\n",
    "        time.sleep(5)\n",
    "        for j in driver.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\"):\n",
    "            brand.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//a[@class = 'IRpwTa']\"):\n",
    "            desc.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\"):\n",
    "            price.append(l.text)\n",
    "        for m in driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\"):\n",
    "            discount.append(m.text)\n",
    "    \n",
    "       \n",
    "\n",
    "    sunglasses = pd.DataFrame({})\n",
    "    sunglasses['Brand'] = brand[0:100]\n",
    "    sunglasses['Description'] = desc[0:100]\n",
    "    sunglasses['Price'] = price[0:100]\n",
    "    sunglasses['Discount'] = discount[0:100]\n",
    "    print(sunglasses)\n",
    "    \n",
    "\n",
    "# Calling Function\n",
    "flipkart_sunglass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCmTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Review_Summary Ratings  \\\n",
      "0            Brilliant       5   \n",
      "1     Perfect product!       5   \n",
      "2        Great product       5   \n",
      "3    Worth every penny       5   \n",
      "4   Highly recommended       5   \n",
      "..                 ...     ...   \n",
      "94           Wonderful       5   \n",
      "95           Fabulous!       5   \n",
      "96      Classy product       5   \n",
      "97           Must buy!       5   \n",
      "98      Classy product       5   \n",
      "\n",
      "                                     Full_Description  \n",
      "0   The Best Phone for the Money  The iPhone 11 of...  \n",
      "1   Amazing phone with great cameras and better ba...  \n",
      "2   Amazing Powerful and Durable Gadget.  I’m am v...  \n",
      "3   Previously I was using one plus 3t it was a gr...  \n",
      "4   iphone 11 is a very good phone to buy only if ...  \n",
      "..                                                ...  \n",
      "94  Dont think too much guys. perfect phone for da...  \n",
      "95  This is my first I phone and I'm very happy to...  \n",
      "96  Amazing delivery. Got my phone a day before ex...  \n",
      "97  Damn this phone is a blast . Upgraded from and...  \n",
      "98  Finally switched to iOS from android There is ...  \n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "review_summ = []\n",
    "ratings = []\n",
    "full_review = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_review():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for a in url[0:11]:\n",
    "        link = a.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "        \n",
    "    urls = [url_list[0],url_list[1],url_list[2],url_list[3],url_list[4],url_list[5],url_list[6],url_list[7],url_list[8],url_list[9]]    \n",
    "      \n",
    "    for m in urls:\n",
    "        driver.get(m)\n",
    "        time.sleep(2)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\"):\n",
    "            review_summ.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//div[@class = '_3LWZlK _1BLPMq']\"):\n",
    "            ratings.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = 't-ZTKy']\"):\n",
    "            full_review.append(k.text.replace('\\n',\" \"))\n",
    "        \n",
    "       \n",
    "\n",
    "    flipkart = pd.DataFrame({})\n",
    "    flipkart['Review_Summary'] = review_summ[0:99]\n",
    "    flipkart['Ratings'] = ratings[0:99]\n",
    "    flipkart['Full_Description'] = full_review[0:99]\n",
    "    print(flipkart)\n",
    "\n",
    "# Calling Function\n",
    "flipkart_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "    You have to scrape 4 attributes of each sneaker :\n",
    "                1. Brand\n",
    "                2. Product Description\n",
    "                3. Price\n",
    "                4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Brand                                Product Description Discount  \\\n",
      "0       Longwalk           Stylish Combo Pack of 2 Sneakers For Men  50% off   \n",
      "1         Chevit  Lightweight Combo Pack of 02 Trendy Sneakers C...  45% off   \n",
      "2         Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...  72% off   \n",
      "3         Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...  76% off   \n",
      "4   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men  63% off   \n",
      "..           ...                                                ...      ...   \n",
      "95           MOU                                   Sneakers For Men  47% off   \n",
      "96     ROCKFIELD                         Rigel IDP Sneakers For Men  57% off   \n",
      "97      CALCADOS         sneaker for mens and boys Sneakers For Men  58% off   \n",
      "98       SHOEFLY                            SM-607 Sneakers For Men  65% off   \n",
      "99      Magnolia              FUTURE RIDER PLAY ON Sneakers For Men  73% off   \n",
      "\n",
      "   Price  \n",
      "0   ₹499  \n",
      "1   ₹540  \n",
      "2   ₹499  \n",
      "3   ₹474  \n",
      "4   ₹360  \n",
      "..   ...  \n",
      "95  ₹523  \n",
      "96  ₹424  \n",
      "97  ₹829  \n",
      "98  ₹348  \n",
      "99  ₹404  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_sneakers():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for a in url[0:11]:\n",
    "        link = a.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "        \n",
    "    urls = [url_list[0],url_list[1],url_list[2],url_list[3],url_list[4],url_list[5]]    \n",
    "      \n",
    "    for m in urls:\n",
    "        driver.get(m)\n",
    "        time.sleep(2)\n",
    "        for i in driver.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\"):\n",
    "            brand.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//a[@class = 'IRpwTa']\"):\n",
    "            desc.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\"):\n",
    "            price.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\"):\n",
    "            discount.append(l.text)\n",
    "        \n",
    "       \n",
    "\n",
    "    flipkart = pd.DataFrame({})\n",
    "    flipkart['Brand'] = brand[0:100]\n",
    "    flipkart['Product Description'] = desc[0:100]\n",
    "    flipkart['Discount'] = discount[0:100]\n",
    "    flipkart['Price'] = price[0:100]\n",
    "    print(flipkart)\n",
    "\n",
    "# Calling Function\n",
    "flipkart_sneakers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "    then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, \n",
    "    price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Brand                Product Description  \\\n",
      "0                   Puma     Men Fuse Training Sports Shoes   \n",
      "1                   Nike      Unisex PHANTOM Football Shoes   \n",
      "2        PUMA Motorsport      Unisex Mercedes Running Shoes   \n",
      "3                   Nike      Men REACT MILER Running Shoes   \n",
      "4                   Nike         Men AIR ZOOM Running Shoes   \n",
      "..                   ...                                ...   \n",
      "95          Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
      "96              DAVINCHI                       Ustraa black   \n",
      "97                  Nike          Men JORDAN DELTA Sneakers   \n",
      "98  Heel & Buckle London         Men Leather Formal Oxfords   \n",
      "99               Bugatti          Men Solid Casual Sneakers   \n",
      "\n",
      "                          Price  \n",
      "0                      Rs. 7999  \n",
      "1     Rs. 7195Rs. 7995(10% OFF)  \n",
      "2                      Rs. 7999  \n",
      "3    Rs. 9345Rs. 10995(15% OFF)  \n",
      "4   Rs. 11470Rs. 13495(15% OFF)  \n",
      "..                          ...  \n",
      "95                     Rs. 8999  \n",
      "96                     Rs. 8990  \n",
      "97                    Rs. 10995  \n",
      "98                    Rs. 10990  \n",
      "99                     Rs. 8999  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "\n",
    "\n",
    "def myntra_shoes():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.myntra.com/shoes\")\n",
    "    \n",
    "    color_filter = driver.find_element_by_xpath(\"//li[@class = 'colour-listItem']\")\n",
    "    color_filter.click()\n",
    "    driver.get(\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6612.0_13075.0_6612.0%20TO%2013075.0\")\n",
    "    price_filter = driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label\")\n",
    "    price_filter.click()\n",
    "    driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6612.0_13075.0_6612.0%20TO%2013075.0%2C6649.0_13100.0_6649.0%20TO%2013100.0')\n",
    "   \n",
    "        \n",
    "    for a in range(0,5):\n",
    "        for i in driver.find_elements_by_xpath(\"//h3[@class = 'product-brand']\"):\n",
    "            brand.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//h4[@class = 'product-product']\"):\n",
    "            desc.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = 'product-price']\"):\n",
    "            price.append(k.text)\n",
    "    next_url = driver.find_element_by_xpath(\"//li[@class = 'pagination-next']/a\").get_attribute(\"href\")\n",
    "    driver.get(next_url)\n",
    "        \n",
    "       \n",
    "\n",
    "    myntra_shoe = pd.DataFrame({})\n",
    "    myntra_shoe['Brand'] = brand[0:100]\n",
    "    myntra_shoe['Product Description'] = desc[0:100]\n",
    "    myntra_shoe['Price'] = price[0:100]\n",
    "    print(myntra_shoe)\n",
    "\n",
    "# Calling Function\n",
    "myntra_shoes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.\n",
    "     Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.After setting the filters scrape first 10 laptops data.\n",
    "     You have to scrape 3 attributes for each laptop:\n",
    "            1. title\n",
    "            2. Ratings\n",
    "            3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title             Ratings  \\\n",
      "0  (Renewed) HP ZBook 15 G3 Mobile Workstation - ...  4.6 out of 5 stars   \n",
      "1  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.3 out of 5 stars   \n",
      "2  HP Pavilion Gaming 11th Gen Intel Core i7 Proc...  4.0 out of 5 stars   \n",
      "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.0 out of 5 stars   \n",
      "4  (Renewed) Dell Latitude E6540 Laptop (CORE I7 ...  2.7 out of 5 stars   \n",
      "5  Life Digital ZED AIR CX7 (Intel Core i7, 8GB R...  4.3 out of 5 stars   \n",
      "6  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6 ...  3.3 out of 5 stars   \n",
      "7  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  4.1 out of 5 stars   \n",
      "8  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...  5.0 out of 5 stars   \n",
      "9  Life Digital ZED AIR CX7 (Intel Core i7, 4GB R...  4.3 out of 5 stars   \n",
      "\n",
      "      Price  \n",
      "0  1,87,490  \n",
      "1    75,993  \n",
      "2    97,432  \n",
      "3    53,974  \n",
      "4    31,990  \n",
      "5    36,990  \n",
      "6    78,990  \n",
      "7  1,98,590  \n",
      "8    79,990  \n",
      "9    33,990  \n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "ratings = []\n",
    "price = []\n",
    "\n",
    "\n",
    "def Amazon_Laptop():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.amazon.in/\")\n",
    "    \n",
    "    search = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    search.send_keys(\"Laptop\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    i7_filter = driver.find_element_by_xpath(\"//li[@class = 'a-spacing-micro' and @aria-label = 'Intel Core i7']\")\n",
    "    i7_filter.click()\n",
    "    driver.get(\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031&dc&qid=1617247369&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_13\")\n",
    "    i9_filter = driver.find_element_by_xpath(\"//li[@class = 'a-spacing-micro' and @aria-label = 'Intel Core i9']\")\n",
    "    i9_filter.click()\n",
    "    driver.get('https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1617247479&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17')\n",
    "   \n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//h2[@class = 'a-size-mini a-spacing-none a-color-base s-line-clamp-2']\"):\n",
    "            title.append(i.text)\n",
    "    soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    ama_rating = soup.find_all(['span'], class_ = \"a-icon-alt\")\n",
    "    for i in ama_rating:\n",
    "        ratings.append(i.get_text().replace('\\n',''))\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class = 'a-price-whole']\"):\n",
    "            price.append(k.text)\n",
    "    \n",
    "        \n",
    "       \n",
    "\n",
    "    laptops = pd.DataFrame({})\n",
    "    laptops['Title'] = title[0:10]\n",
    "    laptops['Ratings'] = ratings[0:10]\n",
    "    laptops['Price'] = price[0:10]\n",
    "    print(laptops)\n",
    "\n",
    "# Calling Function\n",
    "Amazon_Laptop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

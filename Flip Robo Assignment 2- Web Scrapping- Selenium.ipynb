{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the\n",
    "    job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n",
    "    \n",
    "        1. first get the webpage https://www.naukri.com/\n",
    "        2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "           in “enter the location” field.\n",
    "        3. Then click the search button.\n",
    "        4. Then scrape the data for the first 10 jobs results you get.\n",
    "        5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Title                                      Company Name  \\\n",
      "0             Data Analyst                             Super India Tech Mark   \n",
      "1             Data Analyst                                 tech mahindra ltd   \n",
      "2             Data Analyst              CONDUENT BUSINESS SERVICES INDIA LLP   \n",
      "3             Data Analyst           GlaxoSmithKline Pharmaceuticals Limited   \n",
      "4             Data Analyst                          Myntra Designs Pvt. Ltd.   \n",
      "5             Data Analyst                          Myntra Designs Pvt. Ltd.   \n",
      "6  Hiring For Data Analyst  Concentrix Daksh Services India Private Limited.   \n",
      "7             Data Analyst                     WEIWO Communication Pvt. Ltd.   \n",
      "8      Senior Data Analyst                                            Cerner   \n",
      "9      Senior Data Analyst                                Cerner Corporation   \n",
      "\n",
      "  Experience                                           Location  \n",
      "0    0-2 Yrs                     Bangalore/Bengaluru(Devalapur)  \n",
      "1    4-8 Yrs                                Bangalore/Bengaluru  \n",
      "2    1-2 Yrs                                Bangalore/Bengaluru  \n",
      "3    2-7 Yrs                                Bangalore/Bengaluru  \n",
      "4    3-6 Yrs                                Bangalore/Bengaluru  \n",
      "5    4-8 Yrs                                Bangalore/Bengaluru  \n",
      "6    2-7 Yrs  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
      "7    5-8 Yrs                        Bangalore/Bengaluru(Ulsoor)  \n",
      "8    3-5 Yrs                                Bangalore/Bengaluru  \n",
      "9    4-9 Yrs                                Bangalore/Bengaluru  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_da():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Analyst\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\").send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    \n",
    "    url = \"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_da()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape\n",
    "    the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "    \n",
    "            1. first get the webpage https://www.naukri.com/\n",
    "            2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "               “Bangalore” in “enter the location” field.\n",
    "            3. Then click the search button.\n",
    "            4. Then scrape the data for the first 10 jobs results you get.\n",
    "            5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                     Data Scientist   \n",
      "1                      Data Scientist - C3 Developer   \n",
      "2  Principal Data Scientist - Product Development...   \n",
      "3                              Senior Data Scientist   \n",
      "4                        Data Scientist - AI ML Team   \n",
      "5       Data Scientist - Algorithm/ Machine Learning   \n",
      "6                              Senior Data Scientist   \n",
      "7                Data Scientist - KPO - IIT/NIT/BITS   \n",
      "8                        Staff Data Scientist (MINT)   \n",
      "9                                     Data Scientist   \n",
      "\n",
      "                          Company Name             Location  \\\n",
      "0                    Fractal Analytics  Bangalore/Bengaluru   \n",
      "1                                                   Chennai   \n",
      "2  Shell India Markets Private Limited  Bangalore/Bengaluru   \n",
      "3                                                 Bangalore   \n",
      "4            hCapital Executive Search                 Pune   \n",
      "5                                       Bangalore/Bengaluru   \n",
      "6                     Avom Consultants          Delhi / NCR   \n",
      "7                                       Bangalore/Bengaluru   \n",
      "8         CustomerXPs Software Pvt Ltd  Bangalore/Bengaluru   \n",
      "9                                       Bangalore/Bengaluru   \n",
      "\n",
      "                                         Description  \n",
      "0  Job description Role Brief: As a NLP Data Scie...  \n",
      "1  Job description The Role Potential candidate w...  \n",
      "2  Job description Principal Data Scientist - Pro...  \n",
      "3  Job description Data Scientist with relevant e...  \n",
      "4  Job description We are seeking sharp, energeti...  \n",
      "5  Job description Roles & Responsibilities :  - ...  \n",
      "6  Job description To Contribute to model generat...  \n",
      "7  Job description - Looking for Data Scientists ...  \n",
      "8  Job description Your Opportunity To fulfill th...  \n",
      "9  Job description  Looking for a Data Scientist ...  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "job_description = []\n",
    "url_list = []\n",
    "\n",
    "\n",
    "def naukri_ds():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\").send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click() \n",
    "     \n",
    "    driver.get('https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore')\n",
    "    \n",
    "    urls = driver.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "    for i in urls:\n",
    "        link = i.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "          \n",
    "    for x in url_list[0:15]:\n",
    "        driver.get(x)\n",
    "        time.sleep(5)\n",
    "        for i in driver.find_elements_by_xpath(\"//h1[@class = 'jd-header-title']\"):\n",
    "            job_title.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//a[@class='pad-rt-8'or @class = 'subTitle ellipsis fleft']\"):\n",
    "            comp_name.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//span[@class='location ']/a\"):\n",
    "            location_list.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//section[@class='job-desc']\"):\n",
    "            job_description.append(l.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    jobs['Description'] = job_description[0:10]\n",
    "    print(jobs)\n",
    "    \n",
    "# Calling Function\n",
    "naukri_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage.\n",
    "    \n",
    "    The task will be done as shown in the below steps:\n",
    "        1. first get the webpage https://www.naukri.com/\n",
    "        2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "        3. Then click the search button.\n",
    "        4. Then apply the location filter and salary filter by checking the respective boxes.Then scrape the\n",
    "           data for the first 10 jobs results you get.\n",
    "        5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                                     Data Scientist   \n",
      "1                                     Data Scientist   \n",
      "2                                     Data Scientist   \n",
      "3                                     Data Scientist   \n",
      "4                                     Data Scientist   \n",
      "5  Data Scientist | Python | Machine Learning | D...   \n",
      "6  Data Scientist/Data Analyst - Python/Machine L...   \n",
      "7  GCP Presales AIML Architect & Data Scientist (...   \n",
      "8  GCP Presales AIML Architect & Data Scientist (...   \n",
      "9                    Data Scientist Machine Learning   \n",
      "\n",
      "                             Company Name Experience                Location  \n",
      "0                           NatWest Group    4-8 Yrs             Delhi / NCR  \n",
      "1  itForte Staffing Services Private Ltd.    3-8 Yrs        Gurgaon/Gurugram  \n",
      "2                                  Msg.ai    3-5 Yrs        Gurgaon/Gurugram  \n",
      "3                           NatWest Group    4-8 Yrs        Gurgaon/Gurugram  \n",
      "4                           NatWest Group    4-8 Yrs             Delhi / NCR  \n",
      "5                               Careerera    3-8 Yrs  Noida(Sector-59 Noida)  \n",
      "6                          Change leaders   5-10 Yrs       Mumbai, Ghaziabad  \n",
      "7                 Lecan Solutions Pvt Ltd   6-11 Yrs                   Noida  \n",
      "8                 Lecan Solutions Pvt Ltd   6-11 Yrs                   Noida  \n",
      "9                               Delhivery    1-3 Yrs        Gurgaon/Gurugram  \n"
     ]
    }
   ],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_ds_1():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = 'Delhi / NCR']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = '3-6 Lakhs']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_ds_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_ds_1():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = 'Delhi / NCR']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = '3-6 Lakhs']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_ds_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "comp_name = []\n",
    "location_list = []\n",
    "exp_req = []\n",
    "\n",
    "\n",
    "def naukri_ds_1():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    area = driver.find_element_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "    for s in area:\n",
    "        if s.text == 'Delhi / NCR':\n",
    "            s.click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title = '3-6 Lakhs']\").click()\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_title.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        location_list.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        exp_req.append(l.text)\n",
    "        \n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Title'] = job_title[0:10]\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Experience'] = exp_req[0:10]\n",
    "    jobs['Location'] = location_list[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "naukri_ds_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\"}\n  (Session info: chrome=89.0.4389.90)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-b752d66afb5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mnaukri_ds_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-b752d66afb5b>\u001b[0m in \u001b[0;36mnaukri_ds_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marea\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Delhi / NCR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\"}\n  (Session info: chrome=89.0.4389.90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def naukri_ds_1():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.naukri.com/\")\n",
    "    \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\")\n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    area = driver.find_element_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "    for s in area:\n",
    "        if s.text == 'Delhi / NCR':\n",
    "            s.click()\n",
    "            break\n",
    "\n",
    "naukri_ds_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. \n",
    "    You have to scrape company_name, No. of days ago when job was posted, Rating of the company.This task will be done\n",
    "    in following steps:\n",
    "            1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "            2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "               in “location” field.\n",
    "            3. Then click the search button.\n",
    "            4. Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "               page.\n",
    "            5. Finally create a dataframe of the scraped data.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Company Name Days Posted(ago) Ratings\n",
      "0                     Biz2Credit Inc             30d+     3.8\n",
      "1          Unyscape Infocom Pvt. Ltd             30d+     4.1\n",
      "2                            Genpact              24h     3.8\n",
      "3                           Techlive             30d+     5.0\n",
      "4       Salasar New Age Technologies             30d+     5.0\n",
      "5                            Asquero               6d     4.4\n",
      "6       Salasar New Age Technologies             30d+     3.5\n",
      "7                          Microsoft             30d+     3.9\n",
      "8                            CRMNEXT              11d     3.9\n",
      "9  Accolite Software Private Limited              24h     3.0\n"
     ]
    }
   ],
   "source": [
    "days_ago = []\n",
    "comp_name = []\n",
    "ratings = []\n",
    "\n",
    "\n",
    "def glassdoor():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "    \n",
    "    jobs = driver.find_element_by_xpath('//*[@id=\"SrchHero\"]/div/div[1]/div[1]/div/div/div/ul/li[1]').click()\n",
    "        \n",
    "    search_job = driver.find_element_by_xpath(\"//input[@id = 'KeywordSearch']\").send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "    driver.find_element_by_xpath(\"//input[@class='loc']\").clear().send_keys(\"Noida\")\n",
    "    \n",
    "    \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@id='HeroSearchButton']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span\"):\n",
    "        comp_name.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob' or @class = 'd-flex align-items-end pl-std css-mi55ob']\"):\n",
    "        days_ago.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\"):\n",
    "        ratings.append(k.text)\n",
    "    \n",
    "        \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Days Posted(ago)'] = days_ago[0:10]\n",
    "    jobs['Ratings'] = ratings[0:10]\n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "glassdoor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to\n",
    "    scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.The above task will be, done as\n",
    "    shown in the below steps:\n",
    "            1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "            2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "            3. Click the search button.\n",
    "            4. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary\n",
    "               and rating of the company.\n",
    "            5.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Company Name Total Salaries  Average Salary Min and Max Salary\n",
      "0  Tata Consultancy Services    14 salaries   ₹ 6,01,000/yr      ₹336L ₹1,080L\n",
      "1                  Accenture    14 salaries  ₹ 11,51,207/yr      ₹579L ₹2,222L\n",
      "2                  Delhivery    14 salaries  ₹ 12,34,207/yr     ₹452L ₹11,669L\n",
      "3                        IBM    13 salaries   ₹ 7,63,825/yr      ₹589L ₹2,741L\n",
      "4         Ericsson-Worldwide    12 salaries   ₹ 7,32,209/yr      ₹350L ₹1,619L\n",
      "5         UnitedHealth Group    10 salaries  ₹ 13,88,910/yr    ₹1,050L ₹1,500L\n",
      "6         Valiance Solutions     9 salaries   ₹ 8,18,515/yr      ₹504L ₹1,471L\n",
      "7                 Innovaccer     8 salaries  ₹ 12,01,403/yr      ₹623L ₹1,702L\n",
      "8              ZS Associates     7 salaries  ₹ 10,00,000/yr      ₹203L ₹1,817L\n",
      "9                EXL Service     7 salaries  ₹ 11,90,000/yr      ₹578L ₹1,500L\n"
     ]
    }
   ],
   "source": [
    "salary_no = []\n",
    "comp_name = []\n",
    "avg_sal = []\n",
    "min_sal = []\n",
    "\n",
    "def glassdoor_salary():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "    \n",
    "    search_job = driver.find_element_by_xpath(\"//input[@id = 'KeywordSearch']\").send_keys(\"Data Scientist\")\n",
    "    job_loc = driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "    job_area = driver.find_element_by_xpath(\"//input[@class='loc']\").clear().send_keys(\"Noida\")   \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@id='HeroSearchButton']\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "        comp_name.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "        salary_no.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "        avg_sal.append(k.text.replace(\"\\n\",\"\"))\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']\"):\n",
    "        min_sal.append(l.text.replace(\"\\n\",\" \"))\n",
    "      \n",
    "       \n",
    "\n",
    "    jobs = pd.DataFrame({})\n",
    "    jobs['Company Name'] = comp_name[0:10]\n",
    "    jobs['Total Salaries'] = salary_no[0:10]\n",
    "    jobs['Average Salary'] = avg_sal[0:10]\n",
    "    jobs['Min and Max Salary'] = min_sal[0:10]\n",
    "    \n",
    "    print(jobs)\n",
    "\n",
    "# Calling Function\n",
    "glassdoor_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "        1. Brand\n",
    "        2. Product Description\n",
    "        3. Price\n",
    "        4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Brand                                        Description Price Discount\n",
      "0      NuVew              UV Protection Aviator Sunglasses (57)  ₹261  71% off\n",
      "1      NuVew              UV Protection Aviator Sunglasses (57)  ₹195  75% off\n",
      "2   Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758  15% off\n",
      "3   Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹499  50% off\n",
      "4     PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹349  78% off\n",
      "..       ...                                                ...   ...      ...\n",
      "95    PIRASO  UV Protection Rectangular, Cat-eye Sunglasses ...  ₹197  87% off\n",
      "96    PIRASO  UV Protection, Gradient, Riding Glasses Wayfar...  ₹314  87% off\n",
      "97  Fastrack                 UV Protection Oval Sunglasses (60)  ₹689  13% off\n",
      "98    GANSTA       UV Protection, Gradient Oval Sunglasses (58)  ₹270  86% off\n",
      "99    Aislin   UV Protection Wrap-around Sunglasses (Free Size)  ₹568  77% off\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_sunglass():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/\")\n",
    "    pop_btn = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    search_job = driver.find_element_by_xpath(\"//input[@type = 'text']\").send_keys(\"sunglasses\") \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "        \n",
    "    driver.get(\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for i in url:\n",
    "        link = i.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "\n",
    "    for x in url_list[0:6]:\n",
    "        driver.get(x)\n",
    "        time.sleep(5)\n",
    "        for j in driver.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\"):\n",
    "            brand.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//a[@class = 'IRpwTa']\"):\n",
    "            desc.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\"):\n",
    "            price.append(l.text)\n",
    "        for m in driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\"):\n",
    "            discount.append(m.text)\n",
    "    \n",
    "       \n",
    "\n",
    "    sunglasses = pd.DataFrame({})\n",
    "    sunglasses['Brand'] = brand[0:100]\n",
    "    sunglasses['Description'] = desc[0:100]\n",
    "    sunglasses['Price'] = price[0:100]\n",
    "    sunglasses['Discount'] = discount[0:100]\n",
    "    print(sunglasses)\n",
    "    \n",
    "\n",
    "# Calling Function\n",
    "flipkart_sunglass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCmTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Review_Summary Ratings  \\\n",
      "0            Brilliant       5   \n",
      "1     Perfect product!       5   \n",
      "2    Worth every penny       5   \n",
      "3        Great product       5   \n",
      "4   Highly recommended       5   \n",
      "..                 ...     ...   \n",
      "94   Worth every penny       5   \n",
      "95           Fabulous!       5   \n",
      "96           Wonderful       5   \n",
      "97           Fabulous!       5   \n",
      "98      Classy product       5   \n",
      "\n",
      "                                     Full_Description  \n",
      "0   The Best Phone for the Money  The iPhone 11 of...  \n",
      "1   Amazing phone with great cameras and better ba...  \n",
      "2   Previously I was using one plus 3t it was a gr...  \n",
      "3   Amazing Powerful and Durable Gadget.  I’m am v...  \n",
      "4   iphone 11 is a very good phone to buy only if ...  \n",
      "..                                                ...  \n",
      "94  Just go for it without a second thought, if yo...  \n",
      "95  I really liked the budget iPhone. First I thou...  \n",
      "96  Dont think too much guys. perfect phone for da...  \n",
      "97  This is my first I phone and I'm very happy to...  \n",
      "98  Amazing delivery. Got my phone a day before ex...  \n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "review_summ = []\n",
    "ratings = []\n",
    "full_review = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_review():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for a in url[0:11]:\n",
    "        link = a.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "        \n",
    "    for m in url_list:\n",
    "        driver.get(m)\n",
    "        time.sleep(4)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class = '_2-N8zT']\"):\n",
    "            review_summ.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//div[@class = '_3LWZlK _1BLPMq']\"):\n",
    "            ratings.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = 't-ZTKy']\"):\n",
    "            full_review.append(k.text.replace('\\n',\" \"))\n",
    "        \n",
    "       \n",
    "\n",
    "    flipkart = pd.DataFrame({})\n",
    "    flipkart['Review_Summary'] = review_summ[0:99]\n",
    "    flipkart['Ratings'] = ratings[0:99]\n",
    "    flipkart['Full_Description'] = full_review[0:99]\n",
    "    print(flipkart)\n",
    "\n",
    "# Calling Function\n",
    "flipkart_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "    You have to scrape 4 attributes of each sneaker :\n",
    "                1. Brand\n",
    "                2. Product Description\n",
    "                3. Price\n",
    "                4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Brand                                Product Description  \\\n",
      "0   French Connection                                   Sneakers For Men   \n",
      "1        M K FOOTWEAR  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
      "2              Chevit     Casual Sneakers Shoes For Men Sneakers For Men   \n",
      "3        Robbie jones  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
      "4              Chevit                                   Sneakers For Men   \n",
      "..                ...                                                ...   \n",
      "95              Birde                White Casual Shoes Sneakers For Men   \n",
      "96           Magnolia            Combo Pack Of 4 Casual Sneakers For Men   \n",
      "97          ROCKFIELD  Combo Pack of 2 Latest Collection Stylish Casu...   \n",
      "98              Creer  Casual Loafers, Sneakers Shoes for Men Pack of...   \n",
      "99  French Connection  Rockstyle Trending Multicolor Ultralight canva...   \n",
      "\n",
      "   Discount Price  \n",
      "0   60% off  ₹799  \n",
      "1   65% off  ₹349  \n",
      "2   72% off  ₹499  \n",
      "3   62% off  ₹379  \n",
      "4   76% off  ₹474  \n",
      "..      ...   ...  \n",
      "95  60% off  ₹599  \n",
      "96  62% off  ₹377  \n",
      "97  60% off  ₹399  \n",
      "98  60% off  ₹398  \n",
      "99  60% off  ₹799  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "url_list = []\n",
    "\n",
    "def flipkart_sneakers():\n",
    "    driver = webdriver.Chrome(r\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'ge-49M' or @class = 'ge-49M _2Kfbh8']\")\n",
    "    for a in url[0:11]:\n",
    "        link = a.get_attribute('href')\n",
    "        url_list.append(link)\n",
    "        \n",
    "    for m in url_list:\n",
    "        driver.get(m)\n",
    "        time.sleep(4)\n",
    "        for i in driver.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\"):\n",
    "            brand.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//a[@class = 'IRpwTa']\"):\n",
    "            desc.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\"):\n",
    "            price.append(k.text)\n",
    "        for l in driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']\"):\n",
    "            discount.append(l.text)\n",
    "        \n",
    "       \n",
    "\n",
    "    flipkart = pd.DataFrame({})\n",
    "    flipkart['Brand'] = brand[0:100]\n",
    "    flipkart['Product Description'] = desc[0:100]\n",
    "    flipkart['Discount'] = discount[0:100]\n",
    "    flipkart['Price'] = price[0:100]\n",
    "    print(flipkart)\n",
    "\n",
    "# Calling Function\n",
    "flipkart_sneakers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "    then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, \n",
    "    price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Brand            Product Description     Price\n",
      "0                        Nike    Men Run Swift Running Shoes  Rs. 3247\n",
      "1                    Red Tape              Men Walking Shoes  Rs. 6495\n",
      "2                     MENGLER              Men Walking Shoes  Rs. 2189\n",
      "3        Walkstyle By El Paso                  Running Shoes  Rs. 7299\n",
      "4       HRX by Hrithik Roshan    Men Metaflash Running Shoes   Rs. 594\n",
      "..                        ...                            ...       ...\n",
      "95                   Roadster             Men Solid Sneakers  Rs. 6999\n",
      "96  United Colors of Benetton          Men Textured Sneakers  Rs. 3247\n",
      "97                     Reebok     Women Studio Skye Training  Rs. 6495\n",
      "98                 HIGHLANDER                   Men Sneakers  Rs. 2189\n",
      "99                       Puma  Men Cell Pharos Running Shoes  Rs. 7299\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "\n",
    "\n",
    "def myntra_shoes():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.myntra.com/shoes\")\n",
    "    \n",
    "    color_filter = driver.find_element_by_xpath(\"//li[@class = 'colour-listItem']\").click()\n",
    "    driver.get(\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6612.0_13075.0_6612.0%20TO%2013075.0\")\n",
    "    time.sleep(3)\n",
    "    price_filter = driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label\").click()\n",
    "    driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6612.0_13075.0_6612.0%20TO%2013075.0%2C6649.0_13100.0_6649.0%20TO%2013100.0%2C6649.0_13099.0_6649.0%20TO%2013099.0')\n",
    "   \n",
    "    for a in range(0,5):\n",
    "        for i in driver.find_elements_by_xpath(\"//h3[@class = 'product-brand']\"):\n",
    "            brand.append(i.text)\n",
    "        for j in driver.find_elements_by_xpath(\"//h4[@class = 'product-product']\"):\n",
    "            desc.append(j.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class = 'product-price']/span/span\"):\n",
    "            price.append(k.text)\n",
    "    next_url = driver.find_element_by_xpath(\"//li[@class = 'pagination-next']/a\").get_attribute(\"href\")\n",
    "    driver.get(next_url)\n",
    "        \n",
    "       \n",
    "\n",
    "    myntra_shoe = pd.DataFrame({})\n",
    "    myntra_shoe['Brand'] = brand[0:100]\n",
    "    myntra_shoe['Product Description'] = desc[0:100]\n",
    "    myntra_shoe['Price'] = price[0:100]\n",
    "    print(myntra_shoe)\n",
    "\n",
    "# Calling Function\n",
    "myntra_shoes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.\n",
    "     Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.After setting the filters scrape first 10 laptops data.\n",
    "     You have to scrape 3 attributes for each laptop:\n",
    "            1. title\n",
    "            2. Ratings\n",
    "            3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     L-Ratings     Price\n",
      "0  Lenovo Yoga 9 11th Gen Intel Core i7 14-inch 4...    5 out of 5  1,67,990\n",
      "1  (Renewed) HP ZBook 15 G3 Mobile Workstation - ...    No Ratings    83,990\n",
      "2  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.6 out of 5    76,500\n",
      "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.3 out of 5    54,999\n",
      "4  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  2.7 out of 5  1,98,590\n",
      "5  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  4.3 out of 5  1,35,490\n",
      "6  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  4.3 out of 5  2,59,990\n",
      "7  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  3.3 out of 5  1,20,800\n",
      "8  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...  3.3 out of 5    78,990\n",
      "9  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6 ...  4.1 out of 5  2,27,200\n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "ratings = []\n",
    "price = []\n",
    "link = []\n",
    "\n",
    "def Amazon_Laptop():\n",
    "    driver = webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver.get(\"https://www.amazon.in/\")\n",
    "    \n",
    "    search = driver.find_element_by_id(\"twotabsearchtextbox\").send_keys(\"Laptop\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']\").click()\n",
    "    \n",
    "    i7_filter = driver.find_elements_by_xpath(\"//a[@class = 'a-link-normal s-navigation-item']/span\")\n",
    "    for i in i7_filter:\n",
    "        if i.text == 'Intel Core i7':\n",
    "            i.click()\n",
    "            break\n",
    "    i9_filter = driver.find_elements_by_xpath(\"//a[@class = 'a-link-normal s-navigation-item']/span\")\n",
    "    for j in i9_filter:\n",
    "        if j.text == 'Intel Core i9':\n",
    "            j.click()\n",
    "            break\n",
    "      \n",
    "    Title = driver.find_elements_by_xpath(\"//span[@class = 'a-size-medium a-color-base a-text-normal']\")\n",
    "    for k in Title[0:10]:\n",
    "        title.append(k.text)\n",
    "    Price = driver.find_elements_by_xpath(\"//span[@class = 'a-price-whole']\")\n",
    "    for l in Price[0:10]:\n",
    "        price.append(l.text)\n",
    "    \n",
    "    url = driver.find_elements_by_xpath(\"//a[@class = 'a-link-normal a-text-normal']\")\n",
    "    for d in url[0:10]:\n",
    "        link.append(d.get_attribute('href'))\n",
    "    for e in link:\n",
    "        driver.get(e)\n",
    "        try:\n",
    "            rate = driver.find_element_by_xpath(\"//span[@id ='acrCustomerReviewText']\")\n",
    "            rate.click()\n",
    "            Ratings = driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "            ratings.append(Ratings.text)\n",
    "        except NoSuchElementException as e:\n",
    "            ratings.append(\"No Ratings\")     \n",
    "       \n",
    "\n",
    "    laptops = pd.DataFrame({})\n",
    "    laptops['Title'] = title[0:10]\n",
    "    laptops['L-Ratings'] = ratings[0:10]\n",
    "    laptops['Price'] = price[0:10]\n",
    "    print(laptops)\n",
    "\n",
    "# Calling Function\n",
    "Amazon_Laptop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
